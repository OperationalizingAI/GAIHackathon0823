Unknown Speaker  0:06  
If there's something you want to say, you just say,

Unknown Speaker  0:08  
and you don't want

Unknown Speaker  0:11  
to set your Hi,

Speaker 1  0:15  
this is the character of their spiritual book,

Unknown Speaker  0:19  
which is FCDAO

Unknown Speaker  0:20  
But he's here. at this event.

Unknown Speaker  0:32  
told you

Unknown Speaker  0:40  
Is food here I'll turn it over to John

Unknown Speaker  0:44  
Jr. we've already started out just sharing those five sides of this excited in those you knew were in bars shitless and so we have just like we need to have to

Speaker 2  1:29  
talk about the United States and so let's go to our office you know we can be some whatever videos of this chat ops and stuff and so on basically help you to come over got a job and

Speaker 2  1:47  
that was so I was trying to do selected I wanted to pick people who I knew had no shows

Unknown Speaker  2:12  
has come up with a bunch of times, of course the outcome

Speaker 2  2:21  
right let's figure out if there's something we can say at the heart of the industry and they'll the other one. Another narrative, I think this gentleman, I think

Unknown Speaker  2:35  
that's thinking about, like, what was the earliest

Unknown Speaker  2:38  
and we weren't trying to,

Unknown Speaker  2:40  
like we were just trying to figure it out. And

Speaker 2  2:43  
so, Patrick, we've literally sort of evolved something amazing. And I was wondering like, what

Unknown Speaker  2:52  
kind of jumpstart that here so

Speaker 2  2:54  
another sort of potential outcome something about what people think the people that we work with the enterprise, that sort of really important stuff

Unknown Speaker  3:06  
like what is what we can say that does come down to so and I want to make sure we keep an ongoing conversation,

Unknown Speaker  3:13  
whatever

Unknown Speaker  3:14  
people works. One more couple more things.

Unknown Speaker  3:21  
Right now the agenda is

Speaker 2  3:22  
sort of like it's gonna click it doesn't last 24 hours, totally change your mind four times. The position here, but I think we're going to start off with probably all morning around some slide presentation to just just whenever started yesterday at breakfast, I'm like, Oh my god. This is such a comprehensive overview of what's going on. This would be a great framework start get everybody on the same page in the same way that Chris was like, we were meeting people in common language. So at first I was like keeping

Unknown Speaker  4:01  
to be in sunlight, but describe, at least started. So, so yeah, please

Unknown Speaker  4:56  
speak up.

Speaker 2  4:57  
So comedones morning, just a great conversation, and then the plan as planes go, it could change by lunchtime will probably be to the point where I want to up lunch again. or open spaces style ideas to stand up and say, hey, I want to work on this thing. Is anybody interested? We'll put it on the board, and we'll stick it and then we'll probably depending on the size, I mean the American town here but the vote will probably wind up with deciding four or five weeks and into the rest of the week is different is for different breakout rooms, so probably for breakout rooms.

Unknown Speaker  5:37  
And then the only thing I want to try to do everything in morning looks kind of like what we do with jeans, robins that we do. Yes. So we're just constantly

Unknown Speaker  5:54  
sort of trying to do this.

Unknown Speaker  5:58  
And I'm gonna play Slusher

Speaker 2  6:00  
students greatest hackathon. And what he does, he basically works in your group stuck in Oh no calm knows how to do it now bring him over circle around the groups and just say what are you guys working on with the average status you just sit and listen again all this can change after lunch So with that but he is new. We've known each other since credible presentation. He doesn't want to finish I don't think he can show but he's got a baseline for us all to Josephine.

Unknown Speaker  7:20  
Morning everyone,

Speaker 2  7:21  
I'll represent happening. Technologies I've worked with some of you in the past

Unknown Speaker  7:29  
Daymond and Alex

Unknown Speaker  7:34  
just happen to be here

Speaker 2  7:35  
and yeah, I mean I'm the Director of Innovation Group and tea. So let's go around. Let's just go by the order actually.

Unknown Speaker  7:48  
Introduce just introduce

Speaker 3  7:57  
people I'm currently as of last Wednesday, so I knew your interest around operationalizing AI and having the opportunity to talk with Patrick the challenge is how to get paid is constantly working on the software. And so my executives, they look at margin industry technicians are more likely to Kant's shadow mechanics for

Speaker 4  8:23  
bootcamp to hear DAO in here and go back engineer. And so there's this there's this sort of mechanics mindset. And as you start getting into AI, it's this deep technical stuff. How do we start bridging in and making this more usable and accessible to technical people? So that's sort of the concept I'm leading up and says, I'm just here to remind you,

Unknown Speaker  8:47  
I had on wheels

Speaker 4  9:00  
been working with John and David Patrick, for many years

Unknown Speaker  9:11  
I've had a few

Speaker 4  9:12  
brushes with AI in my career, and every time it didn't work out, but I've been very interested in

Speaker 4  9:26  
a very broad discussion that we have different levels, how it impacts people. We manage those things together. So I'm hoping to give people computational models so

Unknown Speaker  9:48  
Florida so

Speaker 1  9:58  
yeah, I'm really interested in AI and really most interested in modern something that obviously how much data and how good of the data does

Unknown Speaker  10:13  
it use speech is

Speaker 1  10:16  
my background is also a combination of all the various

Speaker 1  10:26  
Steven Miguel, I'm Director of Product Innovation at Symantec. And I'm really excited to be here. I mean, I part of the DevOps group and community there for several years now. And it's what I love about this, too, is, you know, yeah, there's this sort of shared origin story in terms of the DevOps space, but everyone's really passionate about technology and

Speaker 3  10:48  
learning and moving to the next thing and then you're familiar with that and then seeing how to introduce air and so really excited to

Unknown Speaker  10:54  
be exploring AI here. With this group.

Unknown Speaker  10:57  
I'm primarily interested

Speaker 5  10:59  
right now in the security and privacy aspects of these large language models. You know,

Speaker 6  11:04  
I think there's two sort of worst case scenarios here like one is, everyone rushes to deploy this and you know, there's some big data incidents and we get instant because of that for everyone's so risk averse. They don't know, you know, how to quantify risks. You know,

Unknown Speaker  11:19  
they don't get leverage to the extent that they can and you don't see

Unknown Speaker  11:21  
the value, at least at large enterprises cyber, it does

Speaker 3  11:24  
tend to be more risk averse and so really want to get better at quantifying those risks and thinking about

Speaker 7  11:29  
them and really think through that and you know, sharing best practices and so forth, models so that you can't balance you know, value. CTO, founded our cannabis business extra research about four years ago and today my background is really product creator, probably the best products in the security space. But also build networks and run it organizations and I kind of get to do a little bit of all of that today, which is the best American, maybe sometimes, not always the best everything but that's a pleasure to be here and it's great to meet some people I have other folks I've known for a long time. Yeah, hi, I'm Damon Edwards. I met a lot of people in this room. But back in my DevOps consulting days, Alex and I ran a consulting company John worked best for a little bit. We worked on basically large IT operations problem, Patrick's presenting called DevOps. And it was really fun to be part of that. That whole rise. And Alex and I started a software company called Run deck. solver. That to me, Judy, there and

Speaker 8  12:44  
Alex fella until Until recently, and I think the excitement about generative AI is really this idea there's all this computing power in the world, right? And we have a way to unlock a lot of that through this linguistic layer that we can put on top of it, I think reminds me the early days of the web, right from it, even the early days of DevOps, right but couldn't really define what exactly it is. We know something could some great stuff that's going to come out of this. So my biggest interest is around operational stuff, right?

Speaker 9  13:19  
So how do we actually leverage it to solve with this problems? Fascinated by the lower level, you know, technology, the models, whatnot, but I realized, you know, you gotta specialize somewhere. Thank you. How do you feel about talking about to do good things? is interesting. Hey, I'm a Chris quarry. Err, my backgrounds in mathematics enumerative combinatorial species specific. Got into DevOps that was a gateway to complexity science for me, so I organized DevOpsDays Atlanta, also organized the only map camp in North America if you're familiar with Wardley mapping, also deep into Value Stream Mapping. I work as a consultant for a firm called Inspire I live in. They tagged me into a hackathon project that they did internally to get it production alized ended up at DevOpsDays, Chicago for the global organizers Summit, pitch to open space on platform engineering and one on platforms for LLM which is how I bumped into John there and ended up here a couple of weeks later. So really, seeing the same patterns are the DevOps, your individual practitioner, you can use your

Speaker 3  14:39  
credit card and just go sign up for this stuff. But how do we pull it in

Speaker 10  14:43  
to a fortune 500 safely? And where's that threshold between classic AI and what is the real differentiator with the generative AI? Underneath all this is really the spot I'm trying to zoom in on so again, honored to be here. So charmed life. Glad to see some familiar faces and look forward to seeing what we figured out this week. My name is Colin McNamara. Okay, cool. My name is Colin McNamara I spend most of my time as a partner at always cool brands, approximate time collaborating with people around here in other places, my main focus in with with generative AI and what's going on now is using it to drive narrative driven business right, to be able to take some of the things that I have learned in the hyperscale world, especially in hyperscale operations and use these tools to increase communication to increase quality and specifically in my current world, to be able to increase quality across the distributed supply chain. I have this kind of vision in my head and I'm curious where it where it develops, where the consumers and how they consume their goods, that these tools will bring a level of transparency to the food they eat, the things that they drink, and what they put in their bodies and then they're with their families. I'm hoping here that I can learn more and collaborate with you all.

Colin McNamara  16:15  
My name is Patrick DuBois. And I just love learning like, anytime there's something new. I'm really trying to understand the impact on what it does. After I don't know how many years of DevOps, I was very bored with DevOps, to be honest. And one of the things I always do is also trying to change my role and what I do and I kind of was running out of that. And I wanted to get into the data science, but I didn't feel like the data science guy yet. And played around with video automation during COVID because I hated presenting myself and I wanted to automate myself like that. So I got into video and generative AI and that space. I thought nobody was listening and then boom, the world had and yeah, it's just been excited to learn and all the possibilities of what worked what doesn't,

Unknown Speaker  17:13  
but the same time I'm VP engineering at Shoebat. We're

Unknown Speaker  17:16  
also rolling out generative

Speaker 12  17:18  
AI things, because we're a sales content management system. And so also happy to share the learnings and the pings and all the stuff we have there. So yeah, it's like all the layers interested. Bring it on

Speaker 12  17:39  
I think my name is Mark Aiko. My story is a lot like Patrick's and John's is actually within two days of talking to them. I talked to John probably for me four or five months ago, because this is the most exciting thing ever. And then Patrick and I got in the same week got on there. This is the most exciting thing ever. But my background I've known a lot of you for a long time is venture backed startups, cloud computing, things like that and about eight and eight months ago now I stepped down and CEO of my company was trigger mesh and we did cloud integration. Because I was sort of burnout and I've been touching at cable on the screen. And then I realized I was such a lousy student and the GF degenerate when I was young. That I was gonna play catch up and as I get older, I'm a great student. I'm taking notes. I'm writing books just for the fun of like learning. And I'm like, Who is this

Speaker 3  18:36  
guy? But I write a newsletter called The artificially intelligent enterprise.

Speaker 13  18:42  
On substack. I have a consulting agency while I tried to figure out what I do when I grow up, which, like I already grew up, probably never figure it out, but I'm really happy to be here. It's really great to see. I've known Damon and Alex for 15 years, Patrick and John close to that as well. And looking forward to knowing all of you until the end and we'll

Speaker 13  19:18  
get back to the the degenerate that doesn't live this week. Hi, my name is Rob and I have known a lot of you legends for a long time or at least known about you. I'm a huge fan. Really excited to be here. My specific interest is a little bit closer to how this impacts cyberphysical systems and and I specifically work multiple different government agencies, government groups, they want to do all of these things, but they usually tend to be about 10 steps behind because of just a whole variety of things that get in the way. So I really want to focus on how we leverage all of the coolness of generative AI, how it can support cyber physical systems. And then furthermore, how we can support some of the really cool systems that

Unknown Speaker  20:15  
the different government agencies

Speaker 13  20:22  
everybody, trace been, let's say, I work with the MITRE

Unknown Speaker  20:26  
Corporation. I come out of

Speaker 5  20:27  
a group within the MITRE Corporation called the advanced software innovation lab. I don't know what that really means other than Software Architect and I focus on digital transformation, not big DT but small DT How can we apply process, apply culture changes, how do we help people and how do we apply the technology? So getting after DevStack ops principles and agility and all of the buzzwords but making the buzzwords real? First of all, absolutely humbled to be in this room. I have to say that nervous for babies, you know, these people are gonna need our food. So, guys, this is incredible, humbled and very honored to be with you all. Today. There are so many things that are bursting at the seams on that with my work at with mitre, I primarily am focusing with you. That's the thing double bound for me about two decades since I focus on a

Speaker 3  21:21  
single area. I've always been very bullish on my goals, but

Speaker 6  21:26  
the momentum that the army specific hands to adopt change the support and advice and the undersecretary of the army, they realize we've got to change and we've got the chief generative AI is going to play a key role in that not just for the end users, but how do we apply it to the SDLC which kind of takes me to where I'm really interested. I want to look at generative AI for the SDLC. And so how do I build better software, the entire gamut? It applies, but we also have to understand the security concerns that we talked about looking at the SDLC for the models themselves. How do we secure them? How do we test them? How do we validate? That takes me to my third area of big concern, which is for security of the models, but also how can we improve security using the models? So again, tons of things that I'm interested in today, I feel like a kid in a candy store already, but just really excited to be here I am ceflix Joe Shannon? i Let's see. I've been in this industry for over 30 years. No job type of software developers carrying me as the industry disrupter started and I'm here because I have been working in corporate environments and small environments. Super excited about generative AI, hoping to see some level

Unknown Speaker  23:06  
of security from the start. And I was like absolutely not getting there all these amazing people. And coming up with

Unknown Speaker  23:31  
totally just the most busy right

Unknown Speaker  23:47  
so I sent you 15 Guys later excited

Speaker 14  24:05  
so we exercise here and again. John said please make us interactive. It was spent five or six hours yesterday

Unknown Speaker  24:25  
when we get to lunch

Unknown Speaker  24:35  
so this

Unknown Speaker  24:36  
quickly. We always kind of start with why

Speaker 2  24:42  
are companies really trying to use team experience which I think

Unknown Speaker  24:46  
sounds like a lot of people are saying journey

Speaker 2  24:49  
with that and try to understand like everybody, sort of our customers live, which I disagree and then try to get out a lot and try to solve those challenges by bringing people in services and technologies and

Unknown Speaker  25:00  
the bottom left to see their every system is perfectly designed

Unknown Speaker  25:04  
for Deming. So that's why we have to continuously improve this one so

Unknown Speaker  25:07  
excited about some stuff to share today because

Unknown Speaker  25:10  
I hopefully we can

Unknown Speaker  25:12  
do some some stocks. With that, like with Jeremy, I

Speaker 15  25:19  
think we all have different herded in this room we have different

Speaker 16  25:24  
things like we're locking down we can't do anything right now there's a skier and strikers all this data was trained on what all these capabilities we're not doing anything to other organizations that are like we're

Unknown Speaker  25:34  
all in everybody get your own opening I account.

Unknown Speaker  25:38  
Just go crazy to

Speaker 4  25:40  
other organizations that are forming these governing bodies, and sort of the concept of a chief AI officer and then every company's chief AI officer now, but and then people said this right security is a must drive compliance auditability and I don't have to probably remind everybody all the lawsuits are coming out daily on the data that the underlying crazy stuff that will assault. There will be some terms that I'm gonna make some assumptions on for everybody sort of training embedding, encoding and decoding for token limits training model parameters, comp, engineering comp,

Unknown Speaker  26:20  
injection,

Speaker 4  26:21  
model, fine tuning, and reinforcement learning human feedback. We have details on all of these if you want to go you can go as deep as you want, within reason, but I'm gonna make some assumptions that you guys understand most of these terms. of service you are debating or concerning.

Unknown Speaker  26:55  
This is

Speaker 4  27:01  
sort of our point of view. I think what resonates with a lot of folks here is the outcomes. What's sort of the end state that our enterprises are trying to reach, and really start there and work our way backwards. And as John indicated, there's some terms that we're throwing out, we're kind of throwing out this concept of a monolithic large language model, versus sort of foundational model. And the thing that we were talking about yesterday is like a monolithic model is a model that they don't give you an API to kind of interact with it, but you can't take your corpus of data and fine tune that model to your heart's content. Whereas if the foundational

Speaker 2  27:38  
models you can take the foundational model, you can do or other sorts of things to fine tune into a specific tasks. Tasks may be smaller in scope, or they want to generalize to other tasks, but that's kind of the sort of the definition we're throwing around again. We want everybody to keep that

Speaker 3  28:01  
dream of yours into the work

Speaker 4  28:08  
either, so just Yeah, so again, with the model at the Bell Labs, we feel like it's a good place to start. You open the eyes of the world and Robert so the world that a great place to start. Many people may move down that road for long periods of time, but there may be data where you don't want that data round tripping us to Microsoft or Google or whomever you may, by regulation have to keep that in your data center. Right? You can't let it leave walls. So for us, it's really again, focusing on those capabilities, but we do believe that the sort of ensemble of fine tuned foundational models will become a lot of the production use cases that we will you know that our industry will help DevStack ops, if you will into production that's started with that last mile

Speaker 2  29:01  
of integrations is key, again, integrating with your existing operations, your existing dev SEC ops pipelines is key. And then you really have to have a lot of feedback. You have

Speaker 3  29:13  
to have sort of a cross account pipeline to take these things again,

Speaker 4  29:16  
from the dead test world, use the staging world manage production, we'll share some high levels of architectures on what we think but this is the hope is that we can beat this thing up over the next few days and have something that we can always gain some consensus on. I'll pause here before we move forward. Are you just curiosity or achiever or Juber hypothesis that enterprises will train their models that fine tuning is going to be good enough or will there be like for let's just not say you're sort of saying these longtail, like very specific ones think fine tuning is good enough versus like what they did with like a balloon or CVP where their large use case because you know I don't know what they were they released it yet maybe they have been they've definitely built it but they were scared because some of the problems of the underlying data they didn't want to read Yeah, I do believe that a lot of early people with a lot of money burning a hole in their pocket had gone out and bought GPUs and like, we're gonna build this model scratch right. I don't know, one if the business cases will. Some of them definitely will from scratch. But because of the commercially viable foundational models

Speaker 13  30:40  
and the floods, those are coming out. I think it might be a lot of people might start there and then they determined that these foundational models, they can't audit them enough or the data to manage them at Providence may then opt in for building their own. But I think this foundational model is going to lower the bar for people to figure that out. To that point, I think regardless, we're going to make the same kind of architectural trade off decisions, right? Should I own my own model? Should I build it from scratch? Leveraging foundational models?

Speaker 4  31:12  
Should they be using what? I promised prompts to some enterprises, a mix of all those, each one of them different service. This is one of those. It depends. And we have to do the trade offs and one of the conversations this week might be after getting after some of those trade offs have a better idea. Because I am seeing people invest a lot of money in models that they don't understand. Why exactly it is certainly take aof technologies right now. A lot of companies are in succession so it's alive. Ai comes on suspect spectrum from people like having clear guidance. They're so sad

Speaker 6  32:06  
as you're watching is this how do you extend that wasn't enough sense. And it's your point at what precipice to build versus what principles do you buy? And then those other sort of considerations at that time said it's going to be a common out there earlier,

Unknown Speaker  32:27  
we're not going to stop the

Speaker 6  32:28  
conversation again. Except we can get the beginning of the conversation started. start to get others and industry involved in the conversation. Part of the trade offs they wanted to add was a lot of people believe when they look at chat TPT is the one model and they're going to train or tune it.

Speaker 4  32:47  
I think what we've seen in reality is that it's gonna be a lot of models right? For example, I only recently find out

Unknown Speaker  33:23  
already feels like oh one

Speaker 4  33:24  
LM console, kind of like my my things kind of was a lesson

Unknown Speaker  33:30  
that wrong and that's why

Unknown Speaker  33:32  
it will never end

Unknown Speaker  33:34  
and make it your own.

Speaker 6  33:36  
Right and they're also more at the point where Chechi to use a bit off to the side. It's a it's a big thing that made a big splash that opened up to democratize

Unknown Speaker  33:45  
the whole idea of AI.

Speaker 12  33:47  
That's great. We already know that you can't train let's say a specific software area based on what I'm looking at ready to do with Microsoft we'll talk about that later we need to be training on on by acknowledged I actually believe that there's probably room for us to think about jumpstarting different domains models for different domains where as experts we can be having this discussion so this one is around Python or this one is around a particular language or a particular namespace. I'd be curious just this week to understand the security aspect of it because it's the first time we've had like, these are open models so we know what the weights are and what the parameters but how does security people who can see it, audit something with 40 billion parameters and weights and stuff that is still essentially a black box so

Speaker 6  34:50  
cool I just stone it out like that's potential blueprint. Yeah

Speaker 6  35:01  
All right. So again, please jump in. Just gonna take a high level view of the last 90 days of announcements and this is just a fraction of the presentation

Unknown Speaker  35:20  
I'll start at the top,

Speaker 6  35:21  
right please jump in Palantir at the top left, right there AIP and sort of global governance. You do it versus Cool guys. Let me see.

Speaker 13  35:40  
So again, starting here on the left, right, the AIP platforms released for cattle here I'm sure many of you guys know Palantir right a lot about government contracts and things of that nature. So they released this March timeframe, and then similar timeframe h2o dot AI, which I'll demonstrate some of their capabilities open source

Speaker 2  36:02  
project. You guys are interested check on the

Unknown Speaker  36:05  
discord

Speaker 17  36:06  
and we can all chat pretty frequently and they have to a show

Unknown Speaker  36:11  
GBT analyst h2o which is an outlet studio

Unknown Speaker  36:16  
for training I'm

Speaker 4  36:17  
going to demo. One maybe both of those if anyone wants to demo today right now, but I hadn't expected time again open source community that focuses on AI. So we'll talk about them but they released these two products, which are all open source ServiceNow. And video obviously made a bunch of partnerships on GPUs for their CMDB event management, incident management, all of that ITSM space along with hooking face to ServiceNow and the release of Star

Speaker 4  37:14  
out there talking about fully governance, right lineage and try tracking integration with vector stores being able to release open source, trained neural foundation models, LM evaluation gateways and model features. So they're, they're expanding and part of their catalog for this was exciting along with our acquisition of Mosaic

Unknown Speaker  37:37  
which we were running before a project obviously cohere and

Speaker 4  37:43  
tropics announcements with AWS and cohere. When they first started, they were actually sitting on Google and they had asked us to help them migrate into clouds. Then they kind of went silent for about three weeks after that partnership with us, so they're offering both embeddings and nominations along with obviously, Azure open AI as models and then on the the models so so one of the things I asked yesterday and says your questions and we recorded also a personal Slack channel. I want to know what he thought was like what's the sort of skinny What should I do Facebook Oh yeah, yeah, right so I mean, Facebook as people may not know it right but they hired some really, really original AI folks like fossa created digits and they have sessions on and in my view that they've been doing for energy based models and a lot of work, they've actually been doing a ton of work in this space, but it's just kind of been behind the scenes, if you will. And everybody obviously knows it, but the models that they released are all commercially viable. And so on a Saturday, Monday B there is a 30 million parameter model but they didn't release it because of hallucinations and quality so they released a 70 billion parameter model I have several other longer models running In my lab, which I'll show you guys, but I think the key there is is that that commercial viability. So if you're planning on building a company, up to 700 million users, you can use those foundational models to train them to your heart's content. A lot of people are not, so I can do things. Microsoft obviously partnered with open AI, but there's a lot of issues with what those models are trained on. Now also partnering with folks like Facebook on

Speaker 2  39:53  
validation models that to your point the the weights and the provenance of data and it's all in public so people can look at that

Colin McNamara  40:00  
and opt in to see if a my use case

Unknown Speaker  40:03  
legally, etc, etc, and

Speaker 2  40:05  
use this model because the data that's turned off, we've been working with AWS on our integration.

Unknown Speaker  40:13  
And so what's interesting there are proteins that are almost like

Speaker 4  40:16  
a catalogue that you can choose from. So you put here or here that have their own bedrock, that you just select the models that you want or bring your own. So you have the same API across that you use, but it's immediately in your VPC in your account of productive zone. And they haven't explored this yet, but you can see in the documentation, that they allow you to put that fine tuning layer on top of their models already, so that for us was one of the reasons why we say like, no, it's customer only. It's very contained in the VPC and it's extendable with our own models and then kind of do the training if you want to do that. So just wanted to call that out. Very accessible then from that perspective is tremendous. Yes. Question two. We're going to

Unknown Speaker  41:20  
do everything I need to do at this point

Unknown Speaker  41:29  
just want to see the other ones that are

Speaker 4  41:43  
here, conversation that we had are the same person so I probably should build an awareness It

Speaker 12  42:04  
shouldn't be the question I asked myself, Why do I have to have these arguments? Why does what's flooding them? Do they have to matter to me as the person that's building tests and training, as I started thinking about that level, so I used to teach this week because of certain techniques for pushing the score towards nice and there's this layer of ELS versus whatever, whatever maybe like next, just more family members so the broader question and asking myself it's actually how do you properly abstract your optics using proper term? But how do you do it in such that there's two goals one, those details they don't, they're not mired in those

Speaker 6  42:49  
details. But to to like Shannon were taught in RSA. Your biggest thing is like, you know, you can't push it up. Why can't you just start building secure and software from time to show.

Unknown Speaker  43:00  
Why is it these days

Speaker 1  43:05  
all the terms I mean, honestly an LM for cybersecurity, we don't believe

Unknown Speaker  43:14  
in this bigger problem set where we are still continuing to

Unknown Speaker  43:17  
vote on security, right. And if you look at,

Speaker 2  43:20  
just do a little quick service and look at the OWASP Top 10 tokens

Unknown Speaker  43:47  
Future conversation about

Unknown Speaker  43:49  
safety versus security actually talking about this they came a conversation I had with jubaland Cseh so do you

Speaker 4  43:59  
missiles versus three strikes I'll leave that right here but it was a very interesting conversation because it was a lot of narrative flying through, right? They can handle bursts strikes, and everyone's now going to try to protect against missiles, safety versus security, that the overloading security is especially as we're thinking about the abstractions not the station's like where are where does the bifurcation, safety or strikes and then secure I mean, that all comes down to risk profile. Like that's to say of the same coin on like your risk surface or threat surface depending on how you want to chalk it up. But this is really, we ran into the same concerns bringing cloud in large orders, but this is why I'm pushing platform for LLM that there's a walled garden within an organization where a lot of this is abstracted out and they don't

Unknown Speaker  44:55  
clean platform like in a

Speaker 4  44:57  
perfect world. They don't know where their codes running, they commit to source

Speaker 14  45:01  
control and they get a link, here's your endpoint. And it's permeable enough that they can come in and see how the sausage is getting made if they're interested. But it's to your point like you can't know all the things like It's literally impossible to expect the developer to be on top of all the security, what model they're running, what Cloud they're not going to be an expert on all this stuff. Legal.

Speaker 6  45:29  
Reality is actually so the question is how do we get back to a place where folks can if they need to, or want to, but we've, we've got so many complicated

Speaker 4  45:45  
views. We have words that mean the same thing duplicated a differentiated, ad nauseam. Honestly, I feel like at this point, there's so many duplicate words out there that we've actually gotten to the point where it doesn't have any.

Unknown Speaker  46:08  
the haves and the Savior of the AI right? It's like that's never gonna happen.

Unknown Speaker  46:19  
Actually do the same thing.

Unknown Speaker  46:28  
You

Speaker 10  46:29  
bring up the unique terms, how each LM interpret some differently a train of different terms in my mind, it brings up something that that you mentioned tracing in that the different LMS for different use cases and you know, I think back in the hyperscale world, and you all must have bumped into the space. We all have that codex of what these three letter acronyms are, and that's all in the confluence or the wikis and that's all in the incident management. And taking is really interesting to me to think like okay, in an apple in a use case of application like in DOD, full of three letter acronyms full of special words. Not only how does one take a LM ER model trained externally and patch that internally to for that use case. But then like what what security vectors does that open up? You know, what, what type of new prompt injection can be done by using a different acronym

Unknown Speaker  47:28  
or open and do some serious

Unknown Speaker  47:36  
work and

Speaker 14  47:39  
forever interesting from that perspective to think about

Unknown Speaker  47:45  
them about

Speaker 14  47:47  
things like work security, safety, really, really trying to get to it. And I think it's about what value

Speaker 12  48:00  
value is a whole different problem, right? And I think now is a resilience. I think a lot of those words now who merging into actually trying to create durable, resilient, you know, customer and manage

Speaker 14  48:15  
products and capabilities, and ignoring security for me lately has meant less and less I hate to say

Colin McNamara  48:24  
think that I

Unknown Speaker  48:25  
will say the word

Speaker 14  48:25  
resilience is a very interesting thing. And this was all together.

Colin McNamara  48:29  
And then at the same time, it's got to get out because I think ultimately, and I've been saying this for like a couple years now, software trust like do you trust all the products on your laptop to you? Which were made and he's making it right. And I think it goes back to that I love what I didn't even go out there. Cancel my gosh. And yeah, and I think, you know, what, the that's one of the things it was like 10 years ago. What did we predict? We predicted that most software was gonna move into a private state at some point closer to customers. And then we did one recently around. What was that gonna mean? It's really interesting to see that a customer just sensitive cares about all the things they're gonna care about.

Speaker 14  49:26  
For me, because that's going to be there and I think that's the most interesting piece of this is listen to customer care, you desperately care about. They're gonna care about this case. I want to use something from a group of people and it represents the best knowledge around my specific domain. And if it's flawed, I'm going to have to have a way to to that slot happen. And the reality is if you looked at generative AI and Chechi Beatty coming in and all these things, they traded on a bunch of junk data, and you're getting things out of it, but unfortunately even like, right so when this nation and all the stuff of you put good data in real experience and real information, they become super valuable to the point where I actually think there's gonna be a next generation of value. It's gonna get created from these and now all of a sudden, and the best experts in the world are gonna be on the hunt

Speaker 14  50:33  
I want everybody to tell you something. I've gotten my hands on Chris if you haven't coffee with him Starbucks. You want one again next year?

Speaker 14  51:05  
Yeah, I just like I think one really valuable thing you could potentially do this week. It's not some of these terms, traditional terms on to their equivalents for AI and so like, the safety and security topic, like in my mind, the differentiator is threat models, right. So like safety you have a sort of non deterministic threat model and random things happen, you know, there's some probability of bird strike, we got to protect against that. Security is more about an adversarial threat model, you know, we're intelligent actor. And so like, you know, things like BIAs are more you know, the safety model, right, you know, the model they use as intended, but not behaving in an appropriate way. Whereas things like data, exfiltration attacks, you know, data exploitation attacks, those are sort of more security, you mentioned resilience, and there's sort of robustness notions in AI that maybe are related to that. So anyway, just throwing that out there. I think all the differentiating to me versus nervous Aryan person, snappy, scary, some things. It's going it's a destructive capability to your value creation has been so to me, the more we can simplify it, the better. It's going to actually because we'll all be having commonality to the terms to get into, I think the word, the word stuff, insecurity.

Speaker 15  52:30  
It's just gotten to the point where we are all talking to each other and that's actually

Speaker 2  52:37  
I'm really curious about what we come up with the skip to I'm your turn and we are in agreement on that.

Unknown Speaker  52:52  
Thinking of it as an instruction becomes an answer to

Speaker 2  53:00  
the whole blameless post incident review situation that are we building safe to fail systems

Unknown Speaker  53:07  
where people it's

Speaker 7  53:08  
okay for them to make mistakes and stop questioning like, did they do it on purpose or not? And like move away from the ad hominem and be like, how do we make it impossible for them? To screw it up like that again?

Unknown Speaker  53:38  
So again, let's get into some of our heavier stuff. This is our conversation before we get into the crazy stuff. You get one intervention for 15 minutes. This is the corner

Unknown Speaker  54:14  
so yeah.

Speaker 14  54:21  
As you can see here in the center, there's been a lot of guys talk about stacks and architectures that are coming out. This one was released in June and it's already kind of deprecated so things are moving super individually. Right. And with that, sort of

Speaker 15  54:40  
it was released in June, and then it was released as well, but again, it's advanced. The last 30 days. 30 days seems like a lifetime 60 days. But we've kind of put together this and we were kind of kicking this around yesterday, this is for everybody to give us feedback on please,

Speaker 10  55:01  
as a community but we kind of have broken established so make your hierarchical levels. But again, this is something for us all to talk about, at the top layer of the sort of Gennai aiops architecture. We have a lot a lot of folks in the retreat generation with the vector stores where people are taking

Unknown Speaker  55:21  
a corpus of data, and

Speaker 2  55:23  
they're chunking that data up based on whatever it may be. If it's images, there's different strategies. If there's sentences or paragraphs or things of that nature, breaking up these pieces of data or elements and data into bite sized chunks and storing them into vector space. And a lot of folks and product are tiny, and suddenly we'll go over many of the vector stores but this is an area where a lot of folks are starting right now to deal with First Nations to try to create some

Unknown Speaker  55:53  
sort of utility on how the large mining

Unknown Speaker  55:55  
farms are responding and giving

Speaker 18  55:57  
them grounding in those things. But at the same time to to take it from just a question answer into something that could be stitched together into other cleaner casts or metadata and things of that nature to be able to relate to those things. So that would be good. So that'd be tagging sort of case IDs events, right customer IDs is

