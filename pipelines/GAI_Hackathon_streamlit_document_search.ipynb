{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nVU23yHni3Ux"},"outputs":[],"source":["%pip install -q langchain streamlit openai pypdf sentence_transformers docarray"]},{"cell_type":"markdown","metadata":{"id":"X-YDsHXxN2DN"},"source":["# Simple Streamlit Web App\n","\n","This app is based on langchainAI's streamlit repo found here - https://github.com/langchain-ai/streamlit-agent\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1692892824322,"user":{"displayName":"Colin McNamara","userId":"11900919394687908359"},"user_tz":240},"id":"czbI0oXbiw6-","outputId":"60e13e9c-ccd4-4cad-de3b-eda7c386711e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting doc_search_app.py\n"]}],"source":["%%writefile doc_search_app.py\n","import os\n","import tempfile\n","import streamlit as st\n","from langchain.chat_models import ChatOpenAI\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.memory import ConversationBufferMemory\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.callbacks.base import BaseCallbackHandler\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.vectorstores import DocArrayInMemorySearch\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","st.set_page_config(page_title=\"GA: Chat with Documents\", page_icon=\"\")\n","st.title(\" GAI Hackathon : Chat with Documents\")\n","\n","\n","@st.cache_resource(ttl=\"1h\")\n","def configure_retriever(uploaded_files):\n","    # Read documents\n","    docs = []\n","    temp_dir = tempfile.TemporaryDirectory()\n","    for file in uploaded_files:\n","        temp_filepath = os.path.join(temp_dir.name, file.name)\n","        with open(temp_filepath, \"wb\") as f:\n","            f.write(file.getvalue())\n","        loader = PyPDFLoader(temp_filepath)\n","        docs.extend(loader.load())\n","\n","    # Split documents\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n","    splits = text_splitter.split_documents(docs)\n","\n","    # Create embeddings and store in vectordb\n","    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","    vectordb = DocArrayInMemorySearch.from_documents(splits, embeddings)\n","\n","    # Define retriever\n","    retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5, \"fetch_k\": 10})\n","\n","    return retriever\n","\n","\n","class StreamHandler(BaseCallbackHandler):\n","    def __init__(self, container: st.delta_generator.DeltaGenerator, initial_text: str = \"\"):\n","        self.container = container\n","        self.text = initial_text\n","\n","    def on_llm_new_token(self, token: str, **kwargs) -> None:\n","        self.text += token\n","        self.container.markdown(self.text)\n","\n","\n","class PrintRetrievalHandler(BaseCallbackHandler):\n","    def __init__(self, container):\n","        self.container = container.expander(\"Context Retrieval\")\n","\n","    def on_retriever_start(self, query: str, **kwargs):\n","        self.container.write(f\"**Question:** {query}\")\n","\n","    def on_retriever_end(self, documents, **kwargs):\n","        # self.container.write(documents)\n","        for idx, doc in enumerate(documents):\n","            source = os.path.basename(doc.metadata[\"source\"])\n","            self.container.write(f\"**Document {idx} from {source}**\")\n","            self.container.markdown(doc.page_content)\n","\n","\n","openai_api_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n","if not openai_api_key:\n","    st.info(\"Please add your OpenAI API key to continue.\")\n","    st.stop()\n","\n","uploaded_files = st.sidebar.file_uploader(\n","    label=\"Upload PDF files\", type=[\"pdf\"], accept_multiple_files=True\n",")\n","if not uploaded_files:\n","    st.info(\"Please upload PDF documents to continue.\")\n","    st.stop()\n","\n","retriever = configure_retriever(uploaded_files)\n","\n","# Setup memory for contextual conversation\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","\n","# Setup LLM and QA chain\n","llm = ChatOpenAI(\n","    model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key, temperature=0, streaming=True\n",")\n","qa_chain = ConversationalRetrievalChain.from_llm(\n","    llm, retriever=retriever, memory=memory, verbose=True\n",")\n","\n","if \"messages\" not in st.session_state or st.sidebar.button(\"Clear message history\"):\n","    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n","\n","for msg in st.session_state.messages:\n","    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n","\n","user_query = st.chat_input(placeholder=\"Ask me anything!\")\n","\n","if user_query:\n","    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n","    st.chat_message(\"user\").write(user_query)\n","\n","    with st.chat_message(\"assistant\"):\n","        retrieval_handler = PrintRetrievalHandler(st.container())\n","        stream_handler = StreamHandler(st.empty())\n","        response = qa_chain.run(user_query, callbacks=[retrieval_handler, stream_handler])\n","        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"]},{"cell_type":"markdown","metadata":{"id":"aqb_QS25TSk7"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YeNLTTJSY5NM"},"outputs":[],"source":["!streamlit run doc_search_app.py &>/content/doc_search_app_logs.txt &"]},{"cell_type":"markdown","metadata":{"id":"ifux-mmzcTQK"},"source":["## Find the IP of your instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":789,"status":"ok","timestamp":1692892825107,"user":{"displayName":"Colin McNamara","userId":"11900919394687908359"},"user_tz":240},"id":"nQz0WaTTcTQK","outputId":"50b324f0-aa04-404d-ba58-e8c218feaf33"},"outputs":[{"name":"stdout","output_type":"stream","text":["104.196.207.82\n","Copy this IP into the webpage that opens below\n"]}],"source":["!curl ipv4.icanhazip.com\n","!echo \"Copy this IP into the webpage that opens below\""]},{"cell_type":"markdown","metadata":{"id":"1XkNhk9abV29"},"source":["## Expose the Streamlit app on port 8501"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DDegT-jZ2Q5","outputId":"475da202-ea70-48b8-b14c-1afd09bfe0b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K\u001b[?25hnpx: installed 22 in 4.656s\n","your url is: https://real-adults-like.loca.lt\n"]}],"source":["!npx localtunnel --port 8501\n","!echo \"Click on the link, and paste the IP from above to authenticate\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPRzfelIOATN38HvG+SvQq2","provenance":[{"file_id":"19szl0IxZdzRJcmJbZTJNvk4sgBzxe38L","timestamp":1692893057231}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
